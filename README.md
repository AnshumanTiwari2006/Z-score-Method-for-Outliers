ğŸ•µï¸â€â™‚ï¸ Outlier Detection & Removal using the Z-Score Method
A foundational data preprocessing technique for identifying and managing extreme values using the Z-Score (3-Sigma) Rule
âœ… Best suited for features that follow â€” or closely resemble â€” a normal (Gaussian) distribution

ğŸ“Œ Overview
This project demonstrates how to detect and handle outliers in a numerical feature using statistical principles rooted in the properties of the normal distribution. The analysis focuses on the income column from a customer dataset, applying the widely used Z-score method to ensure data quality before modeling.

The Jupyter Notebook guides you through a structured workflow:

ğŸ“Š Data Loading & Initial Inspection: Load the dataset and examine the size and basic characteristics of the target column
ğŸ“ˆ Distribution Check: Visualize the data using histograms and compute skewness to assess suitability for Z-score-based treatment
ğŸ§® Statistical Boundary Setup: Use the mean and standard deviation to define outlier thresholds based on the 3-Sigma Rule
ğŸ§¹ Outlier Management: Apply two standard strategies â€” removal or capping â€” to address extreme values
ğŸ” Final Validation: Confirm the impact of treatment using summary statistics to ensure outliers no longer distort the data

ğŸ“¥ Installation
All required libraries can be installed with a single pip command:

pip install pandas numpy seaborn matplotlib

ğŸ’¡ Tip: Use a virtual environment to maintain clean, isolated dependencies.

ğŸ“ Dataset
The analysis uses a sample customer dataset named Outlier.csv.

Primary Feature: income â€” a numerical column representing customer earnings
Supporting Features: age, gender, days_on_platform, and purchases (used for context, not modified)
While the Z-score method assumes near-normality, the notebook includes diagnostic checks to evaluate whether the data meets this condition before proceeding.

ğŸ“ Z-Score Method Explained
The Z-score quantifies how far a data point lies from the mean, measured in units of standard deviation.

According to the Empirical (3-Sigma) Rule:

~68% of data falls within Â±1Ïƒ
~95% within Â±2Ïƒ
~99.7% within Â±3Ïƒ
Thus, any observation beyond Â±3 standard deviations from the mean is considered statistically rare and flagged as an outlier.

ğŸ”¢ Key Insight
Even if a feature isnâ€™t perfectly normal, the Z-score method can still be useful when the distribution is reasonably symmetric â€” though results should always be validated visually and statistically.

ğŸ§¹ Outlier Handling Strategies

âœ‚ï¸ Trimming (Removal)
Records with income values outside the Â±3Ïƒ range are excluded from the dataset. This reduces the total sample size but ensures extreme values donâ€™t influence analysis.

âŒ Trade-off: Simplicity vs. potential loss of valuable observations

ğŸ§¢ Capping (Winsorization)
Instead of deletion, extreme income values are adjusted to the nearest statistical boundary (upper or lower limit). This retains all rows while neutralizing the distorting effect of outliers.

âœ… Recommended for machine learning pipelines where preserving sample size is critical

ğŸ“ˆ Results & Validation
After applying capping:

The maximum and minimum values align precisely with the calculated 3-sigma limits
Summary statistics reflect a more stable, model-ready distribution
The influence of extreme outliers is effectively eliminated without discarding data
ğŸš€ Ready to Explore?
â€¢ Clone this repository
â€¢ Install dependencies
â€¢ Open the notebook and walk through the full outlier treatment workflow

ğŸ“¬ Feedback & Contributions
Have an idea? Spot an improvement?
ğŸ‘‰ Open an issue or submit a pull request â€” your input is welcome! ğŸ¤
